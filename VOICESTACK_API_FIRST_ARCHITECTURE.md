# Vocal: API-First Architecture
## Generic Speech AI Platform (STT + TTS)
### Monorepo with Auto-Generated OpenAPI & SDKs

---

## ğŸ¯ Architecture Philosophy

**API is the Source of Truth:**
- API defines all schemas, types, and contracts
- OpenAPI spec auto-generated from FastAPI
- SDK auto-generated from OpenAPI spec
- CLI is thin wrapper around SDK
- Type safety everywhere (Pydantic models)

**Generic & Extensible:**
- Registry-based model management (HuggingFace, local, custom providers)
- Supports STT (Speech-to-Text) now, TTS (Text-to-Speech) later
- Pluggable adapters for any model backend
- Provider-agnostic storage and caching

---

## ğŸ“ Monorepo Structure

```
vocal/
â”œâ”€â”€ pyproject.toml              # Root uv workspace config â³ TODO
â”œâ”€â”€ uv.lock                     # uv lockfile â³ TODO
â”œâ”€â”€ README.md                   â³ TODO
â”œâ”€â”€ LICENSE (AGPL-3.0)          â³ TODO
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ api/                    # ğŸ”¥ FastAPI Server (Source of Truth)
â”‚   â”‚   â”œâ”€â”€ vocal_api/          â³ TODO
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI app
â”‚   â”‚   â”‚   â”œâ”€â”€ models/         # Pydantic models (schemas)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.py    # STT models
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ model.py            # Model registry models
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/         # API endpoints by domain
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.py    # STT endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ models.py           # Model management
â”‚   â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ transcription_service.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ model_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py # FastAPI dependencies
â”‚   â”‚   â”‚   â””â”€â”€ config.py       # Settings
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                   # ğŸ§© Shared Core Logic
â”‚   â”‚   â”œâ”€â”€ vocal_core/         â³ TODO
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ registry/       # Generic model registry
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py             # Base registry interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model_info.py       # Model metadata
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ providers/          # Model providers
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ base.py         # Provider interface
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ huggingface.py  # HF provider
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ local.py        # Local models
â”‚   â”‚   â”‚   â”œâ”€â”€ adapters/       # Model adapters (STT/TTS)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py             # Base adapter
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ stt/                # STT adapters
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ whisper.py
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ faster_whisper.py
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ canary.py
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/        # Model storage & cache
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model_store.py      # Generic storage
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ cache.py            # Model caching
â”‚   â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚
â”‚   â”œâ”€â”€ sdk/                    # ğŸ“¦ Auto-Generated Python SDK
â”‚   â”‚   â”œâ”€â”€ vocal_sdk/          â³ TODO (Generate after API)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py       # Main SDK client
â”‚   â”‚   â”‚   â”œâ”€â”€ models/         # Generated from OpenAPI
â”‚   â”‚   â”‚   â”œâ”€â”€ api/            # Generated API methods
â”‚   â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â”œâ”€â”€ openapi-generator-config.yaml
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â””â”€â”€ generate.sh     # Generate from OpenAPI spec
â”‚   â”‚
â”‚   â””â”€â”€ cli/                    # ğŸ’» CLI (Thin wrapper around SDK)
â”‚       â”œâ”€â”€ vocal_cli/          â³ TODO (After SDK)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ main.py         # Typer CLI app
â”‚       â”‚   â”œâ”€â”€ commands/       # CLI commands
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ run.py      # vocal run (transcribe)
â”‚       â”‚   â”‚   â”œâ”€â”€ models.py   # vocal models list/pull/rm
â”‚       â”‚   â”‚   â””â”€â”€ serve.py    # vocal serve (start API)
â”‚       â”‚   â”œâ”€â”€ ui/             # Rich terminal UI
â”‚       â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”‚   â”œâ”€â”€ progress.py
â”‚       â”‚   â”‚   â””â”€â”€ tables.py
â”‚       â”‚   â””â”€â”€ config.py
â”‚       â”œâ”€â”€ pyproject.toml
â”‚       â””â”€â”€ tests/
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-dev.sh            # Development setup â³ TODO
â”‚   â”œâ”€â”€ generate-sdk.sh         # Generate SDK from OpenAPI â³ TODO
â”‚   â””â”€â”€ build-all.sh            # Build all packages â³ TODO
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ api/                    # API documentation â³ TODO
    â”œâ”€â”€ sdk/                    # SDK documentation â³ TODO
    â””â”€â”€ cli/                    # CLI documentation â³ TODO
```

---

## ğŸ”¥ Phase 1: API (Source of Truth)

### Implementation Status: â³ TODO (Start here!)

### 1.1 Core Models (Pydantic Schemas)

**packages/api/vocal_api/models/transcription.py:** â³ TODO
```python
from pydantic import BaseModel, Field, field_validator
from typing import Optional, Literal
from enum import Enum

class TranscriptionFormat(str, Enum):
    """Output format for transcription"""
    JSON = "json"
    TEXT = "text"
    SRT = "srt"
    VTT = "vtt"
    VERBOSE_JSON = "verbose_json"

class TranscriptionRequest(BaseModel):
    """Request schema for transcription"""
    model: str = Field(
        description="Model ID to use for transcription",
        examples=["whisper-large-v3", "voxtral-24b"]
    )
    language: Optional[str] = Field(
        None,
        description="Language code (ISO 639-1). Auto-detect if not provided.",
        examples=["en", "es", "fr"]
    )
    prompt: Optional[str] = Field(
        None,
        description="Optional text to guide the model's style",
        max_length=224
    )
    response_format: TranscriptionFormat = Field(
        TranscriptionFormat.JSON,
        description="Format of the transcription output"
    )
    temperature: float = Field(
        0.0,
        ge=0.0,
        le=1.0,
        description="Sampling temperature"
    )
    timestamp_granularities: list[Literal["word", "segment"]] = Field(
        default_factory=lambda: ["segment"],
        description="Timestamp granularity"
    )
    
    @field_validator("language")
    @classmethod
    def validate_language(cls, v: Optional[str]) -> Optional[str]:
        if v and len(v) != 2:
            raise ValueError("Language must be 2-letter ISO 639-1 code")
        return v

class TranscriptionSegment(BaseModel):
    """A segment of transcribed text with timing"""
    id: int
    start: float = Field(description="Start time in seconds")
    end: float = Field(description="End time in seconds")
    text: str = Field(description="Transcribed text")
    tokens: Optional[list[int]] = None
    temperature: Optional[float] = None
    avg_logprob: Optional[float] = None
    compression_ratio: Optional[float] = None
    no_speech_prob: Optional[float] = None

class TranscriptionWord(BaseModel):
    """Word-level timestamp"""
    word: str
    start: float
    end: float
    probability: Optional[float] = None

class TranscriptionResponse(BaseModel):
    """Response schema for transcription"""
    text: str = Field(description="Full transcribed text")
    language: str = Field(description="Detected or specified language")
    duration: float = Field(description="Audio duration in seconds")
    segments: Optional[list[TranscriptionSegment]] = None
    words: Optional[list[TranscriptionWord]] = None
    
    class Config:
        json_schema_extra = {
            "example": {
                "text": "Hello, how are you today?",
                "language": "en",
                "duration": 2.5,
                "segments": [
                    {
                        "id": 0,
                        "start": 0.0,
                        "end": 2.5,
                        "text": "Hello, how are you today?"
                    }
                ]
            }
        }
```

**packages/api/vocal_api/models/model.py:** â³ TODO
```python
from pydantic import BaseModel, Field, HttpUrl
from typing import Optional, Literal
from datetime import datetime
from enum import Enum

class ModelStatus(str, Enum):
    """Model download/availability status"""
    AVAILABLE = "available"
    DOWNLOADING = "downloading"
    NOT_DOWNLOADED = "not_downloaded"
    ERROR = "error"

class ModelBackend(str, Enum):
    """Model inference backend"""
    FASTER_WHISPER = "faster_whisper"
    TRANSFORMERS = "transformers"
    CTRANSLATE2 = "ctranslate2"
    NEMO = "nemo"
    ONNX = "onnx"
    CUSTOM = "custom"

class ModelProvider(str, Enum):
    """Model provider/source"""
    HUGGINGFACE = "huggingface"
    LOCAL = "local"
    CUSTOM = "custom"

class ModelInfo(BaseModel):
    """Model information schema"""
    id: str = Field(description="Unique model identifier")
    name: str = Field(description="Human-readable model name")
    provider: ModelProvider = Field(description="Model provider")
    description: Optional[str] = None
    size: int = Field(description="Model size in bytes")
    size_readable: str = Field(description="Human-readable size (e.g., '3.1GB')")
    parameters: str = Field(description="Number of parameters (e.g., '1.5B')")
    languages: list[str] = Field(description="Supported languages")
    backend: ModelBackend = Field(description="Inference backend")
    status: ModelStatus = Field(description="Current model status")
    source_url: Optional[HttpUrl] = None
    license: Optional[str] = None
    recommended_vram: Optional[str] = Field(
        None,
        description="Recommended VRAM (e.g., '6GB+')"
    )
    task: str = Field(description="Task type: 'stt' or 'tts'")
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    
    class Config:
        json_schema_extra = {
            "example": {
                "id": "openai/whisper-large-v3",
                "name": "OpenAI Whisper Large V3",
                "provider": "huggingface",
                "size": 3100000000,
                "size_readable": "3.1GB",
                "parameters": "1.5B",
                "languages": ["en", "es", "fr", "de", "..."],
                "backend": "faster_whisper",
                "status": "available",
                "recommended_vram": "6GB+",
                "task": "stt"
            }
        }

class ModelListResponse(BaseModel):
    """List of available models"""
    models: list[ModelInfo]
    total: int

class ModelDownloadRequest(BaseModel):
    """Request to download a model"""
    model_id: str
    quantization: Optional[Literal["int8", "int8_float16", "float16", "float32"]] = None
    provider: Optional[ModelProvider] = ModelProvider.HUGGINGFACE

class ModelDownloadProgress(BaseModel):
    """Model download progress"""
    model_id: str
    status: Literal["downloading", "completed", "error"]
    progress: float = Field(ge=0.0, le=1.0)
    downloaded_bytes: int
    total_bytes: int
    speed_mbps: Optional[float] = None
    eta_seconds: Optional[int] = None
```

---

### 1.2 API Routes (FastAPI Endpoints)

**packages/api/vocal_api/routes/transcription.py:** â³ TODO
```python
from fastapi import APIRouter, UploadFile, File, Form, Depends, HTTPException
from typing import Annotated, Optional
from ..models.transcription import (
    TranscriptionRequest,
    TranscriptionResponse,
    TranscriptionFormat
)
from ..services.transcription_service import TranscriptionService
from ..dependencies import get_transcription_service

router = APIRouter(prefix="/v1/audio", tags=["transcription"])

@router.post(
    "/transcriptions",
    response_model=TranscriptionResponse,
    summary="Transcribe audio",
    description="Transcribe audio file to text using specified model"
)
async def create_transcription(
    file: Annotated[UploadFile, File(description="Audio file to transcribe")],
    model: Annotated[str, Form(description="Model ID")] = "openai/whisper-large-v3",
    language: Annotated[Optional[str], Form(description="Language code")] = None,
    prompt: Annotated[Optional[str], Form(description="Style prompt")] = None,
    response_format: Annotated[
        TranscriptionFormat,
        Form(description="Output format")
    ] = TranscriptionFormat.JSON,
    temperature: Annotated[float, Form(ge=0.0, le=1.0)] = 0.0,
    service: TranscriptionService = Depends(get_transcription_service)
) -> TranscriptionResponse:
    """
    Transcribe an audio file.
    
    **Supported formats:** mp3, mp4, wav, m4a, flac, ogg, webm
    **Max file size:** 25MB
    
    Returns transcription with optional word/segment timestamps.
    """
    file.file.seek(0, 2)
    size = file.file.tell()
    file.file.seek(0)
    
    if size > 25 * 1024 * 1024:
        raise HTTPException(400, "File too large. Max 25MB.")
    
    request = TranscriptionRequest(
        model=model,
        language=language,
        prompt=prompt,
        response_format=response_format,
        temperature=temperature
    )
    
    result = await service.transcribe(file, request)
    return result

@router.post(
    "/translations",
    response_model=TranscriptionResponse,
    summary="Translate audio to English",
    description="Translate audio to English text"
)
async def create_translation(
    file: Annotated[UploadFile, File()],
    model: Annotated[str, Form()] = "openai/whisper-large-v3",
    service: TranscriptionService = Depends(get_transcription_service)
) -> TranscriptionResponse:
    """Translate audio to English."""
    return await service.translate(file, model)
```

**packages/api/vocal_api/routes/models.py:** â³ TODO
```python
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from typing import Optional
from ..models.model import (
    ModelInfo,
    ModelListResponse,
    ModelDownloadRequest,
    ModelDownloadProgress
)
from ..services.model_service import ModelService
from ..dependencies import get_model_service

router = APIRouter(prefix="/v1/models", tags=["models"])

@router.get(
    "",
    response_model=ModelListResponse,
    summary="List models",
    description="List all available models"
)
async def list_models(
    status: Optional[str] = None,
    service: ModelService = Depends(get_model_service)
) -> ModelListResponse:
    """
    List all available models.
    
    **Query params:**
    - status: Filter by status (available, downloading, not_downloaded)
    """
    models = await service.list_models(status_filter=status)
    return ModelListResponse(models=models, total=len(models))

@router.get(
    "/{model_id}",
    response_model=ModelInfo,
    summary="Get model info",
    description="Get detailed information about a specific model"
)
async def get_model(
    model_id: str,
    service: ModelService = Depends(get_model_service)
) -> ModelInfo:
    """Get detailed model information."""
    model = await service.get_model(model_id)
    if not model:
        raise HTTPException(404, f"Model {model_id} not found")
    return model

@router.post(
    "/{model_id}/download",
    response_model=ModelDownloadProgress,
    summary="Download model",
    description="Download a model for local use"
)
async def download_model(
    model_id: str,
    background_tasks: BackgroundTasks,
    request: Optional[ModelDownloadRequest] = None,
    service: ModelService = Depends(get_model_service)
) -> ModelDownloadProgress:
    """
    Start downloading a model.
    
    Returns immediately with initial progress.
    Use GET /models/{model_id}/download/status to check progress.
    """
    background_tasks.add_task(
        service.download_model,
        model_id,
        request.quantization if request else None
    )
    
    return ModelDownloadProgress(
        model_id=model_id,
        status="downloading",
        progress=0.0,
        downloaded_bytes=0,
        total_bytes=0
    )

@router.get(
    "/{model_id}/download/status",
    response_model=ModelDownloadProgress,
    summary="Get download status"
)
async def get_download_status(
    model_id: str,
    service: ModelService = Depends(get_model_service)
) -> ModelDownloadProgress:
    """Check model download progress."""
    status = await service.get_download_status(model_id)
    if not status:
        raise HTTPException(404, "No active download for this model")
    return status

@router.delete(
    "/{model_id}",
    summary="Delete model",
    description="Remove a downloaded model"
)
async def delete_model(
    model_id: str,
    service: ModelService = Depends(get_model_service)
):
    """Delete a downloaded model."""
    await service.delete_model(model_id)
    return {"status": "deleted", "model_id": model_id}
```

**packages/api/vocal_api/main.py:** â³ TODO
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.openapi.utils import get_openapi
from .routes import transcription, models
from .config import settings

app = FastAPI(
    title="Vocal API",
    description="Generic Speech AI Platform (STT + TTS)",
    version="0.1.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.include_router(transcription.router)
app.include_router(models.router)

@app.get("/", tags=["health"])
async def root():
    """API health check"""
    return {
        "status": "ok",
        "message": "Vocal API",
        "version": "0.1.0"
    }

@app.get("/health", tags=["health"])
async def health():
    """Detailed health check"""
    return {
        "status": "healthy",
        "api_version": "0.1.0",
        "models_loaded": True
    }

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title="Vocal API",
        version="0.1.0",
        description="Generic Speech AI Platform (STT + TTS)",
        routes=app.routes,
    )
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi
```

---

## ğŸ“¦ Phase 2: Auto-Generated SDK

### Implementation Status: â³ TODO (Generate after API is ready)

### 2.1 SDK Generation Script

**packages/sdk/scripts/generate.sh:** â³ TODO
```bash
#!/bin/bash
set -e

echo "ğŸ”„ Generating Python SDK from OpenAPI spec..."

cd ../api
uv run uvicorn vocal_api.main:app --port 8000 &
API_PID=$!

sleep 3

curl http://localhost:8000/openapi.json -o ../sdk/openapi.json

kill $API_PID

cd ../sdk
openapi-generator-cli generate \
  -i openapi.json \
  -g python \
  -o . \
  -c openapi-generator-config.yaml \
  --additional-properties=packageName=vocal_sdk

echo "âœ… SDK generated successfully!"
echo "ğŸ“ Installing generated SDK..."
uv pip install -e .

echo "ğŸ‰ Done! SDK ready to use."
```

**packages/sdk/openapi-generator-config.yaml:** â³ TODO
```yaml
packageName: vocal_sdk
projectName: vocal-sdk
packageVersion: 0.1.0
packageUrl: https://github.com/vocal/vocal
generateSourceCodeOnly: false
library: urllib3
```

### 2.2 SDK Client Wrapper

**packages/sdk/vocal_sdk/client.py:** â³ TODO
**packages/sdk/vocal_sdk/client.py:** â³ TODO
```python
"""Vocal SDK Client - High-level wrapper"""
from typing import Optional, BinaryIO, Union
from pathlib import Path
from .api.transcription_api import TranscriptionApi
from .api.models_api import ModelsApi
from .models import (
    TranscriptionResponse,
    ModelInfo,
    ModelListResponse
)
from .configuration import Configuration
from .api_client import ApiClient

class Vocal:
    """
    Vocal SDK Client
    
    Example:
        >>> client = Vocal()
        >>> result = client.transcribe("audio.mp3")
        >>> print(result.text)
    """
    
    def __init__(
        self,
        base_url: str = "http://localhost:11435"
    ):
        """
        Initialize Vocal client
        
        Args:
            base_url: API base URL (default: http://localhost:11435)
        """
        config = Configuration(host=base_url)
        
        self._client = ApiClient(config)
        self._transcription = TranscriptionApi(self._client)
        self._models = ModelsApi(self._client)
    
    def transcribe(
        self,
        file: Union[str, Path, BinaryIO],
        model: str = "openai/whisper-large-v3",
        language: Optional[str] = None,
        **kwargs
    ) -> TranscriptionResponse:
        """
        Transcribe audio file
        
        Args:
            file: Path to audio file or file-like object
            model: Model ID to use
            language: Language code (auto-detect if None)
            **kwargs: Additional parameters
        
        Returns:
            TranscriptionResponse with text and metadata
            
        Example:
            >>> result = client.transcribe("audio.mp3")
            >>> print(result.text)
            "Hello, how are you today?"
        """
        if isinstance(file, (str, Path)):
            with open(file, 'rb') as f:
                return self._transcription.create_transcription(
                    file=f,
                    model=model,
                    language=language,
                    **kwargs
                )
        else:
            return self._transcription.create_transcription(
                file=file,
                model=model,
                language=language,
                **kwargs
            )
    
    def list_models(self, status: Optional[str] = None) -> ModelListResponse:
        """
        List available models
        
        Args:
            status: Filter by status (available, downloading, etc.)
            
        Returns:
            ModelListResponse with list of models
            
        Example:
            >>> models = client.list_models()
            >>> for model in models.models:
            ...     print(f"{model.id}: {model.size_readable}")
        """
        return self._models.list_models(status=status)
    
    def get_model(self, model_id: str) -> ModelInfo:
        """Get model information"""
        return self._models.get_model(model_id)
    
    def download_model(
        self,
        model_id: str,
        quantization: Optional[str] = None
    ):
        """Download a model"""
        return self._models.download_model(
            model_id,
            quantization=quantization
        )
    
    def delete_model(self, model_id: str):
        """Delete a downloaded model"""
        return self._models.delete_model(model_id)
```

---

## ğŸ’» Phase 3: CLI (Using SDK)

### Implementation Status: â³ TODO (After SDK is ready)

**packages/cli/vocal_cli/main.py:** â³ TODO
**packages/cli/vocal_cli/main.py:** â³ TODO
```python
import typer
from rich.console import Console
from typing import Optional
from .commands import models, run, serve

app = typer.Typer(
    name="vocal",
    help="Generic Speech AI Platform (STT + TTS)",
    add_completion=False
)
console = Console()

app.add_typer(models.app, name="models")
app.command()(run.run_command)
app.command()(serve.serve_command)

@app.callback()
def main(
    version: bool = typer.Option(
        False,
        "--version",
        "-v",
        help="Show version"
    )
):
    """Vocal CLI"""
    if version:
        console.print("vocal v0.1.0")
        raise typer.Exit()

if __name__ == "__main__":
    app()
```

**packages/cli/vocal_cli/commands/run.py:** â³ TODO
**packages/cli/vocal_cli/commands/run.py:** â³ TODO
```python
import typer
from pathlib import Path
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn
from vocal_sdk import Vocal
from vocal_sdk.exceptions import ApiException

console = Console()

def run_command(
    audio_file: Path = typer.Argument(
        ...,
        help="Audio file to transcribe"
    ),
    model: str = typer.Option(
        "openai/whisper-large-v3",
        "--model",
        "-m",
        help="Model to use"
    ),
    language: Optional[str] = typer.Option(
        None,
        "--language",
        "-l",
        help="Language code (auto-detect if not specified)"
    ),
    output: Optional[Path] = typer.Option(
        None,
        "--output",
        "-o",
        help="Output file (default: stdout)"
    ),
    format: str = typer.Option(
        "text",
        "--format",
        "-f",
        help="Output format: text, json, srt, vtt"
    ),
    base_url: str = typer.Option(
        "http://localhost:11435",
        "--url",
        help="API base URL"
    )
):
    """
    Transcribe an audio file
    
    Examples:
    
        vocal run audio.mp3
        
        vocal run audio.mp3 --model openai/whisper-large-v3 --language es
        
        vocal run audio.mp3 --output transcript.srt --format srt
    """
    
    if not audio_file.exists():
        console.print(f"[red]Error:[/red] File not found: {audio_file}")
        raise typer.Exit(1)
    
    client = Vocal(base_url=base_url)
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console
    ) as progress:
        task = progress.add_task(
            f"Transcribing {audio_file.name}...",
            total=None
        )
        
        try:
            result = client.transcribe(
                file=audio_file,
                model=model,
                language=language,
                response_format=format
            )
            
            progress.update(task, completed=True)
            
        except ApiException as e:
            progress.stop()
            console.print(f"[red]Error:[/red] {e}")
            raise typer.Exit(1)
    
    if output:
        output.write_text(result.text)
        console.print(f"[green]âœ“[/green] Saved to {output}")
    else:
        console.print("\n" + result.text)
    
    console.print(f"\n[dim]Language: {result.language} | Duration: {result.duration:.1f}s[/dim]")
```

**packages/cli/vocal_cli/commands/models.py:** â³ TODO
**packages/cli/vocal_cli/commands/models.py:** â³ TODO
```python
import typer
from rich.console import Console
from rich.table import Table
from vocal_sdk import Vocal

app = typer.Typer(help="Manage models")
console = Console()

@app.command("list")
def list_models(
    status: Optional[str] = typer.Option(None, "--status", "-s")
):
    """List available models"""
    client = Vocal()
    
    try:
        response = client.list_models(status=status)
        
        table = Table(title="Available Models")
        table.add_column("ID", style="cyan")
        table.add_column("Name", style="white")
        table.add_column("Size", style="yellow")
        table.add_column("Status", style="green")
        
        for model in response.models:
            status_color = {
                "available": "green",
                "downloading": "yellow",
                "not_downloaded": "dim"
            }.get(model.status, "white")
            
            table.add_row(
                model.id,
                model.name,
                model.size_readable,
                f"[{status_color}]{model.status}[/{status_color}]"
            )
        
        console.print(table)
        
    except Exception as e:
        console.print(f"[red]Error:[/red] {e}")
        raise typer.Exit(1)

@app.command("pull")
def pull_model(
    model_id: str = typer.Argument(..., help="Model ID to download"),
    quantization: Optional[str] = typer.Option(None, "--quantize", "-q")
):
    """Download a model"""
    client = Vocal()
    
    console.print(f"ğŸ“¥ Downloading {model_id}...")
    
    try:
        progress = client.download_model(model_id, quantization)
        
        console.print(f"[green]âœ“[/green] Downloaded {model_id}")
        
    except Exception as e:
        console.print(f"[red]Error:[/red] {e}")
        raise typer.Exit(1)

@app.command("show")
def show_model(
    model_id: str = typer.Argument(...)
):
    """Show model details"""
    client = Vocal()
    
    try:
        model = client.get_model(model_id)
        
        console.print(f"\n[bold]{model.name}[/bold]")
        console.print(f"ID: {model.id}")
        console.print(f"Provider: {model.provider}")
        console.print(f"Size: {model.size_readable}")
        console.print(f"Parameters: {model.parameters}")
        console.print(f"Languages: {', '.join(model.languages[:10])}")
        console.print(f"Backend: {model.backend}")
        console.print(f"Status: {model.status}")
        
        if model.description:
            console.print(f"\n{model.description}")
        
    except Exception as e:
        console.print(f"[red]Error:[/red] {e}")
        raise typer.Exit(1)
```

---

## ğŸ—ï¸ Development Workflow

### Step 1: Start with Core Registry â³ TODO
```bash
# 1. Build generic model registry with HuggingFace provider
cd packages/core/vocal_core/registry
# Implement: base.py, model_info.py, providers/huggingface.py

# 2. Build model adapters (start with faster-whisper)
cd ../adapters/stt
# Implement: base.py, faster_whisper.py

# 3. Build storage layer
cd ../../storage
# Implement: model_store.py, cache.py

# 4. Test core functionality
uv run pytest
```

### Step 2: Build API on top of Core â³ TODO
```bash
# 1. Create API schemas (Pydantic models)
cd packages/api/vocal_api/models
# Edit transcription.py, model.py

# 2. Create routes
cd ../routes
# Edit transcription.py, models.py

# 3. Run API
uv run uvicorn vocal_api.main:app --reload

# 4. Check OpenAPI docs
# Visit http://localhost:8000/docs
```

### Step 3: Generate SDK â³ TODO
```bash
# Generate SDK from OpenAPI spec
cd packages/sdk
./scripts/generate.sh

# SDK is now ready at packages/sdk/vocal_sdk/
```

### Step 4: Build CLI using SDK â³ TODO
```bash
# Install SDK
cd packages/sdk
uv pip install -e .

# Build CLI
cd packages/cli
# CLI commands use SDK client

# Test CLI
vocal models list
vocal run audio.mp3
```

---

## âœ… Benefits of This Architecture

1. **Type Safety Everywhere**
   - Pydantic models validate at API
   - SDK has full type hints
   - CLI gets type safety from SDK

2. **Single Source of Truth**
   - API defines all contracts
   - OpenAPI spec auto-generated
   - SDK auto-generated from spec
   - No schema drift

3. **Generic & Extensible**
   - Registry-based model management
   - Provider-agnostic (HuggingFace, local, custom)
   - Supports STT now, TTS later
   - Pluggable adapters for any backend

4. **Easy Testing**
   - Test API directly
   - Mock SDK for CLI tests
   - OpenAPI spec = automatic client tests

5. **Multi-Language Support**
   - Same OpenAPI spec
   - Generate JS/TS SDK: `openapi-generator-cli generate -g typescript-axios`
   - Generate Go SDK: `openapi-generator-cli generate -g go`

6. **Clean Separation**
   - Core = model management & inference
   - API = business logic & HTTP interface
   - SDK = client library
   - CLI = user interface
   - Each can be versioned independently

---

## ğŸš€ Getting Started

```bash
# 1. Create monorepo with uv
mkdir vocal && cd vocal
uv init

# 2. Set up workspace structure
mkdir -p packages/{api,core,sdk,cli}

# 3. Start with Core (registry + adapters)
cd packages/core
# Build generic registry with HuggingFace provider
# Build adapters (faster-whisper, etc.)

# 4. Build API on top of Core
cd packages/api
# Create models, routes, services

# 5. Run API
uv run uvicorn vocal_api.main:app --reload

# 6. Generate SDK
cd packages/sdk
./scripts/generate.sh

# 7. Build CLI
cd packages/cli
# Implement commands using SDK

# 8. Test end-to-end
vocal run audio.mp3
```

---

## ğŸ“¦ Package Dependencies (uv workspace)

**Root pyproject.toml:** â³ TODO
```toml
[project]
name = "vocal"
version = "0.1.0"
requires-python = ">=3.11"

[tool.uv.workspace]
members = [
    "packages/core",
    "packages/api",
    "packages/sdk",
    "packages/cli"
]
```

**packages/core/pyproject.toml:** â³ TODO
```toml
[project]
name = "vocal-core"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "faster-whisper>=1.0.0",
    "huggingface-hub>=0.20.0",
    "torch>=2.1.0",
    "pydantic>=2.5.0",
]
```

**packages/api/pyproject.toml:** â³ TODO
```toml
[project]
name = "vocal-api"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "pydantic>=2.5.0",
    "python-multipart>=0.0.6",
    "vocal-core",
]
```

**packages/sdk/pyproject.toml:** â³ TODO (Generated)
```toml
[project]
name = "vocal-sdk"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "urllib3>=2.0.0",
    "python-dateutil>=2.8.0",
    "pydantic>=2.5.0",
]
```

**packages/cli/pyproject.toml:** â³ TODO
```toml
[project]
name = "vocal"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "typer>=0.9.0",
    "rich>=13.7.0",
    "vocal-sdk",
]

[project.scripts]
vocal = "vocal_cli.main:app"
```

---

## ğŸ¯ Implementation Priority

### Phase 0: Core Foundation (START HERE) âœ… DONE
1. âœ… Generic model registry interface
2. âœ… HuggingFace provider implementation
3. âœ… Model storage & caching layer
4. âœ… Base adapter interface
5. âœ… faster-whisper adapter (first STT model)

### Phase 1: API Layer âœ… DONE
1. âœ… Pydantic models (transcription.py)
2. âœ… API routes (transcription.py)
3. âœ… Services (transcription_service.py)
4. âœ… FastAPI app setup with CORS and health endpoints

### Phase 2: SDK Generation âœ… DONE
1. âœ… OpenAPI spec auto-generation
2. âœ… Python SDK with clean interface
3. âœ… SDK documentation

### Phase 3: CLI â³ TODO
1. CLI commands (run, models, serve)
2. Rich UI components
3. End-to-end testing

---

## ğŸ”‘ Key Design Decisions

1. **HuggingFace as Primary Provider**
   - âœ… Best ecosystem for OSS models
   - âœ… Built-in caching & download management
   - âœ… Easy to extend with custom providers

2. **faster-whisper as Default Backend**
   - âœ… 4x faster than OpenAI Whisper
   - âœ… Same accuracy
   - âœ… Lower memory usage
   - âœ… CTranslate2 optimizations

3. **Registry Pattern for Models**
   - âœ… Supports multiple providers (HF, local, custom)
   - âœ… Easy to add new model types (TTS later)
   - âœ… Centralized model metadata & discovery

4. **API-First Architecture**
   - âœ… Auto-generated SDK & docs
   - âœ… Type-safe everywhere
   - âœ… Easy to build clients in any language

5. **No Auth for POC**
   - Can be added later via middleware
   - Not critical for local/self-hosted deployment

---

This architecture is **generic, extensible, and production-ready**! ğŸ¯
